{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/dasys-lab/comaze-python/blob/gym-env/CoMazeGym_Agent_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BPALy2GEL_vQ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import time\n",
    "import gym\n",
    "\n",
    "\n",
    "class CoMazeGym(gym.Env):\n",
    "  if os.path.isfile(\".local\"):\n",
    "    API_URL = \"http://localhost:16216\"\n",
    "    WEBAPP_URL = \"http://localhost\"\n",
    "  else:\n",
    "    API_URL = \"http://teamwork.vs.uni-kassel.de:16216\"\n",
    "    WEBAPP_URL = \"http://teamwork.vs.uni-kassel.de\"\n",
    "  LIB_VERSION = \"1.3.0\"\n",
    "  \n",
    "  def __init__(self):\n",
    "    self.game = None\n",
    "    self.game_id = None\n",
    "    self.player_id = None\n",
    "    self.action_space = None\n",
    "\n",
    "  def reset(self, options={}):\n",
    "    level = options.get(\"level\", \"1\")\n",
    "    num_of_player_slots = options.get(\"num_of_player_slots\", \"2\")\n",
    "    self.game_id = requests.post(self.API_URL + \"/game/create?level=\" + level + \"&numOfPlayerSlots=\" + num_of_player_slots).json()[\"uuid\"]\n",
    "    options[\"game_id\"] = self.game_id\n",
    "    return self.play_existing_game(options)\n",
    "\n",
    "  def play_existing_game(self, options={}):\n",
    "    if \"look_for_player_name\" in options:\n",
    "      options[\"game_id\"] = requests.get(self.API_URL + \"/game/byPlayerName?playerName=\" + options[\"look_for_player_name\"]).json()[\"uuid\"]\n",
    "\n",
    "    if \"game_id\" not in options or len(options[\"game_id\"]) != 36:\n",
    "      raise Exception(\"You must provide a game id when attending an existing game. Use play_new_game() instead of play_existing_game() if you want to create a new game.\")\n",
    "\n",
    "    player_name = options.get(\"player_name\", \"Python\")\n",
    "    self.game_id = options[\"game_id\"]\n",
    "    print(\"Joined gameId: \" + self.game_id)\n",
    "    player = requests.post(self.API_URL + \"/game/\" + self.game_id + \"/attend?playerName=\" + player_name).json()\n",
    "    self.player_id = player[\"uuid\"]\n",
    "    self.action_space = player['directions'] + ['SKIP']\n",
    "    print(\"Playing as playerId: \" + self.player_id)\n",
    "    self.game = requests.get(self.API_URL + \"/game/\" + self.game_id).json()\n",
    "    print(f'Action Space is {self.action_space}')\n",
    "\n",
    "    while self.game['currentPlayer']['uuid'] != self.player_id:\n",
    "      print(f'Waiting for other player to make first move')\n",
    "      time.sleep(1)\n",
    "      self.game = requests.get(self.API_URL + \"/game/\" + self.game_id).json()\n",
    "\n",
    "    return self.game\n",
    "\n",
    "  def step(self, action, message=None):\n",
    "    moved = False\n",
    "    while not moved:\n",
    "      self.game = requests.get(self.API_URL + \"/game/\" + self.game_id).json()\n",
    "\n",
    "      if not self.game[\"state\"][\"started\"]:\n",
    "        print(\"Waiting for players. (Invite someone: \" + self.WEBAPP_URL + \"/?gameId=\" + self.game_id + \")\")\n",
    "        time.sleep(3)\n",
    "        continue\n",
    "\n",
    "      print(\"Moving \" + action)\n",
    "      print(f'Sending message {message}')\n",
    "      print('---')\n",
    "      self.game = requests.post(self.API_URL + \"/game/\" + self.game_id + \"/move?playerId=\" + self.player_id + \"&action=\" + action).json()\n",
    "      moved = True\n",
    "    \n",
    "    if self.game[\"state\"][\"won\"]:\n",
    "      print(\"Game won!\")\n",
    "      reward = 1\n",
    "    elif self.game[\"state\"][\"lost\"]:\n",
    "      print(\"Game lost (\" + self.game[\"state\"][\"lostMessage\"] + \").\")\n",
    "      reward = -1\n",
    "    else:\n",
    "      reward = 0\n",
    "\n",
    "    if not self.game[\"state\"][\"over\"]:\n",
    "      # wait for other player to make a move before sending back obs\n",
    "      while self.game['currentPlayer']['uuid'] != self.player_id:\n",
    "        print(f'Waiting for other player to make a move')\n",
    "        time.sleep(1)\n",
    "        self.game = requests.get(self.API_URL + \"/game/\" + self.game_id).json()\n",
    "\n",
    "    return self.game, reward, self.game[\"state\"][\"over\"], None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.spaces import Box, Discrete, Dict, MultiBinary\n",
    "import numpy as np\n",
    "\n",
    "class CoMazeGymActionWrapper(gym.Wrapper):\n",
    "  def __init__(self, env, vocab_size=10, maximum_sentence_length=1, options={}):\n",
    "    super(CoMazeGymActionWrapper, self).__init__(env)\n",
    "    self.nb_directions = 4\n",
    "    self.actionId2action =  [\"LEFT\", \"RIGHT\", \"UP\", \"DOWN\"]\n",
    "    \n",
    "    self.vocab_size = vocab_size\n",
    "    self.maximum_sentence_length = maximum_sentence_length\n",
    "    self._build_sentenceId2sentence()\n",
    "    \n",
    "    self.nb_possible_actions = self.nb_directions*self.nb_possible_sentences+1 \n",
    "    # +1 accounts for the SKIP action...\n",
    "    self.action_space = Discrete(self.nb_possible_actions)\n",
    "\n",
    "  def _build_sentenceId2sentence(self):\n",
    "    self.nb_possible_sentences = (self.vocab_size+1)**self.maximum_sentence_length\n",
    "    sentenceId2sentence = np.zeros( (self.nb_possible_sentences, self.maximum_sentence_length))\n",
    "    \n",
    "    idx = 1\n",
    "    local_token_pointer = 0\n",
    "    global_token_pointer = 0\n",
    "    while idx != self.nb_possible_sentences:\n",
    "      sentenceId2sentence[idx] = sentenceId2sentence[idx-1]\n",
    "      sentenceId2sentence[idx][local_token_pointer] = (sentenceId2sentence[idx][local_token_pointer]+1)%(self.vocab_size+1)\n",
    "      while sentenceId2sentence[idx][local_token_pointer] == 0:\n",
    "        local_token_pointer += 1\n",
    "        sentenceId2sentence[idx][local_token_pointer] = (sentenceId2sentence[idx][local_token_pointer]+1)%(self.vocab_size+1)\n",
    "      idx += 1\n",
    "      local_token_pointer = 0\n",
    "    \n",
    "    self.sentenceId2sentence = sentenceId2sentence\n",
    "  \n",
    "  def step(self, action):\n",
    "    if not self.action_space.contains(action):\n",
    "      raise ValueError('action {} is invalid for {}'.format(action, self.action_space))\n",
    "    \n",
    "    if action != (self.nb_possible_actions-1):\n",
    "      original_action_direction_id = action // self.nb_possible_sentences\n",
    "      original_action_direction = self.actionId2action[original_action_direction_id]\n",
    "    \n",
    "      original_action_message_id = (action % self.nb_possible_sentences)\n",
    "      original_action_message = self.sentenceId2sentence[original_action_message_id]\n",
    "    else:\n",
    "      original_action_direction = \"SKIP\"\n",
    "      original_action_message = self.sentenceId2sentence[0] #empty message.\n",
    "    \n",
    "    print(f'discrete action {action} -> original action: direction={original_action_direction} / message={original_action_message}')\n",
    "    \n",
    "    return self.env.step(action=original_action_direction, message=original_action_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j8fb8gjDM5jP"
   },
   "outputs": [],
   "source": [
    "env = CoMazeGym()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_env = CoMazeGymActionWrapper(env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wrapped_env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5y_ulJCCM-Bi"
   },
   "outputs": [],
   "source": [
    "# Random Agent\n",
    "import random \n",
    "\n",
    "obs = env.reset()\n",
    "game_over = False\n",
    "while not game_over:\n",
    "  obs, reward, game_over, info = env.step(random.choice(env.action_space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5y_ulJCCM-Bi"
   },
   "outputs": [],
   "source": [
    "# Random Agent with Discrete action wrapper\n",
    "import random \n",
    "\n",
    "obs = wrapped_env.reset()\n",
    "game_over = False\n",
    "while not game_over:\n",
    "  obs, reward, game_over, info = wrapped_env.step(wrapped_env.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ua-MVU_4PXo3"
   },
   "outputs": [],
   "source": [
    "# Nearest Goal Agent\n",
    "# Choose a nearest goal, see if one of your actions can get you there, if so take that action\n",
    "obs = env.reset()\n",
    "game_over = False\n",
    "action_space = env.action_space\n",
    "goals_pos = [goal['position']\n",
    "             for goal in obs['config']['goals']]\n",
    "\n",
    "while not game_over:\n",
    "  goals_pos = [goal['position'] for goal in obs['unreachedGoals']]\n",
    "  agent_pos = obs['agentPosition']\n",
    "  \n",
    "  goal_diffs = [(goal['x'] - agent_pos['x'], goal['y'] - agent_pos['y'])\n",
    "                for goal in goals_pos]\n",
    "  goal_dists = [abs(diff[0])+abs(diff[1]) for diff in goal_diffs]\n",
    "  nearest_goal = goal_dists.index(min(goal_dists)) \n",
    "\n",
    "  print(f'Nearest goal is {obs[\"unreachedGoals\"][nearest_goal]}')\n",
    "  print(f'Nearest goal diff {goal_diffs[nearest_goal]}')\n",
    "\n",
    "  move_x, move_y = goal_diffs[nearest_goal]\n",
    "\n",
    "  if 'LEFT' in action_space and move_x < 0:\n",
    "    action = 'LEFT'\n",
    "  elif 'RIGHT' in action_space and move_x > 0:\n",
    "    action = 'RIGHT'\n",
    "  elif 'UP' in action_space and move_y < 0:\n",
    "    action = 'UP'\n",
    "  elif 'DOWN' in action_space and move_y > 0:\n",
    "    action = 'DOWN'\n",
    "  else:\n",
    "    action = 'SKIP'\n",
    "\n",
    "  obs, reward, game_over, info = env.step(action)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T2m8l6uJVk1-"
   },
   "outputs": [],
   "source": [
    "# Basic RL agent\n",
    "# single-layer NN that takes in current state and learns action\n",
    "# import torch\n",
    "\n",
    "# obs = env.reset()\n",
    "# game_over = False\n",
    "# action_space = env.action_space\n",
    "# goals_pos = [goal['position']\n",
    "#              for goal in obs['config']['goals']]\n",
    "\n",
    "\n",
    "# obs, reward, game_over, info = env.step(action)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BXivOcskf347"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "CoMaze Agent Template",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
